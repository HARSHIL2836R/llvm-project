; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mattr=+sve  -verify-machineinstrs < %s | FileCheck %s
; RUN: llc -mattr=+sve2 -verify-machineinstrs < %s | FileCheck %s

target triple = "aarch64-unknown-linux-gnu"

; Test vector_splice patterns.
; Note that this test is similar to named-vector-shuffles-sve.ll, but it focuses
; on testing all supported types, and a positive "splice index".


; i8 elements
define <vscale x 16 x i8> @splice_nxv16i8(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b) {
; CHECK-LABEL: splice_nxv16i8:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #1
; CHECK-NEXT:    ret
  %res = call <vscale x 16 x i8> @llvm.vector.splice.nxv16i8(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, i32 1)
  ret <vscale x 16 x i8> %res
}

; i16 elements
define <vscale x 8 x i16> @splice_nxv8i16(<vscale x 8 x i16> %a, <vscale x 8 x i16> %b) {
; CHECK-LABEL: splice_nxv8i16:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #2
; CHECK-NEXT:    ret
  %res = call <vscale x 8 x i16> @llvm.vector.splice.nxv8i16(<vscale x 8 x i16> %a, <vscale x 8 x i16> %b, i32 1)
  ret <vscale x 8 x i16> %res
}

; bf16 elements

define <vscale x 8 x bfloat> @splice_nxv8bfloat(<vscale x 8 x bfloat> %a, <vscale x 8 x bfloat> %b) {
; CHECK-LABEL: splice_nxv8bfloat:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #2
; CHECK-NEXT:    ret
  %res = call <vscale x 8 x bfloat> @llvm.vector.splice.nxv8bfloat(<vscale x 8 x bfloat> %a, <vscale x 8 x bfloat> %b, i32 1)
  ret <vscale x 8 x bfloat> %res
}

define <vscale x 4 x bfloat> @splice_nxv4bfloat(<vscale x 4 x bfloat> %a, <vscale x 4 x bfloat> %b) {
; CHECK-LABEL: splice_nxv4bfloat:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #4
; CHECK-NEXT:    ret
  %res = call <vscale x 4 x bfloat> @llvm.vector.splice.nxv4bfloat(<vscale x 4 x bfloat> %a, <vscale x 4 x bfloat> %b, i32 1)
  ret <vscale x 4 x bfloat> %res
}

define <vscale x 2 x bfloat> @splice_nxv2bfloat(<vscale x 2 x bfloat> %a, <vscale x 2 x bfloat> %b) {
; CHECK-LABEL: splice_nxv2bfloat:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #8
; CHECK-NEXT:    ret
  %res = call <vscale x 2 x bfloat> @llvm.vector.splice.nxv4bfloat(<vscale x 2 x bfloat> %a, <vscale x 2 x bfloat> %b, i32 1)
  ret <vscale x 2 x bfloat> %res
}

; f16 elements

define <vscale x 8 x half> @splice_nxv8f16(<vscale x 8 x half> %a, <vscale x 8 x half> %b) {
; CHECK-LABEL: splice_nxv8f16:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #2
; CHECK-NEXT:    ret
  %res = call <vscale x 8 x half> @llvm.vector.splice.nxv8f16(<vscale x 8 x half> %a, <vscale x 8 x half> %b, i32 1)
  ret <vscale x 8 x half> %res
}

define <vscale x 4 x half> @splice_nxv4f16(<vscale x 4 x half> %a, <vscale x 4 x half> %b) {
; CHECK-LABEL: splice_nxv4f16:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #4
; CHECK-NEXT:    ret
  %res = call <vscale x 4 x half> @llvm.vector.splice.nxv4f16(<vscale x 4 x half> %a, <vscale x 4 x half> %b, i32 1)
  ret <vscale x 4 x half> %res
}

define <vscale x 2 x half> @splice_nxv2f16(<vscale x 2 x half> %a, <vscale x 2 x half> %b) {
; CHECK-LABEL: splice_nxv2f16:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #8
; CHECK-NEXT:    ret
  %res = call <vscale x 2 x half> @llvm.vector.splice.nxv2f16(<vscale x 2 x half> %a, <vscale x 2 x half> %b, i32 1)
  ret <vscale x 2 x half> %res
}

; i32 elements
define <vscale x 4 x i32> @splice_nxv4i32(<vscale x 4 x i32> %a, <vscale x 4 x i32> %b) {
; CHECK-LABEL: splice_nxv4i32:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #4
; CHECK-NEXT:    ret
  %res = call <vscale x 4 x i32> @llvm.vector.splice.nxv4i32(<vscale x 4 x i32> %a, <vscale x 4 x i32> %b, i32 1)
  ret <vscale x 4 x i32> %res
}

; f32 elements

define <vscale x 4 x float> @splice_nxv4f32(<vscale x 4 x float> %a, <vscale x 4 x float> %b) {
; CHECK-LABEL: splice_nxv4f32:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #4
; CHECK-NEXT:    ret
  %res = call <vscale x 4 x float> @llvm.vector.splice.nxv4f32(<vscale x 4 x float> %a, <vscale x 4 x float> %b, i32 1)
  ret <vscale x 4 x float> %res
}

define <vscale x 2 x float> @splice_nxv2f32(<vscale x 2 x float> %a, <vscale x 2 x float> %b) {
; CHECK-LABEL: splice_nxv2f32:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #8
; CHECK-NEXT:    ret
  %res = call <vscale x 2 x float> @llvm.vector.splice.nxv2f32(<vscale x 2 x float> %a, <vscale x 2 x float> %b, i32 1)
  ret <vscale x 2 x float> %res
}

; i64 elements
define <vscale x 2 x i64> @splice_nxv2i64(<vscale x 2 x i64> %a, <vscale x 2 x i64> %b) {
; CHECK-LABEL: splice_nxv2i64:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #8
; CHECK-NEXT:    ret
  %res = call <vscale x 2 x i64> @llvm.vector.splice.nxv2i64(<vscale x 2 x i64> %a, <vscale x 2 x i64> %b, i32 1)
  ret <vscale x 2 x i64> %res
}

; f64 elements
define <vscale x 2 x double> @splice_nxv2f64(<vscale x 2 x double> %a, <vscale x 2 x double> %b) {
; CHECK-LABEL: splice_nxv2f64:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ext z0.b, z0.b, z1.b, #8
; CHECK-NEXT:    ret
  %res = call <vscale x 2 x double> @llvm.vector.splice.nxv2f64(<vscale x 2 x double> %a, <vscale x 2 x double> %b, i32 1)
  ret <vscale x 2 x double> %res
}

declare <vscale x 2 x i1> @llvm.vector.splice.nxv2i1(<vscale x 2 x i1>, <vscale x 2 x i1>, i32)
declare <vscale x 4 x i1> @llvm.vector.splice.nxv4i1(<vscale x 4 x i1>, <vscale x 4 x i1>, i32)
declare <vscale x 8 x i1> @llvm.vector.splice.nxv8i1(<vscale x 8 x i1>, <vscale x 8 x i1>, i32)
declare <vscale x 16 x i1> @llvm.vector.splice.nxv16i1(<vscale x 16 x i1>, <vscale x 16 x i1>, i32)

declare <vscale x 2 x i8> @llvm.vector.splice.nxv2i8(<vscale x 2 x i8>, <vscale x 2 x i8>, i32)
declare <vscale x 16 x i8> @llvm.vector.splice.nxv16i8(<vscale x 16 x i8>, <vscale x 16 x i8>, i32)
declare <vscale x 8 x i16> @llvm.vector.splice.nxv8i16(<vscale x 8 x i16>, <vscale x 8 x i16>, i32)
declare <vscale x 4 x i32> @llvm.vector.splice.nxv4i32(<vscale x 4 x i32>, <vscale x 4 x i32>, i32)
declare <vscale x 8 x i32> @llvm.vector.splice.nxv8i32(<vscale x 8 x i32>, <vscale x 8 x i32>, i32)
declare <vscale x 2 x i64> @llvm.vector.splice.nxv2i64(<vscale x 2 x i64>, <vscale x 2 x i64>, i32)

declare <vscale x 2 x half> @llvm.vector.splice.nxv2f16(<vscale x 2 x half>, <vscale x 2 x half>, i32)
declare <vscale x 4 x half> @llvm.vector.splice.nxv4f16(<vscale x 4 x half>, <vscale x 4 x half>, i32)
declare <vscale x 8 x half> @llvm.vector.splice.nxv8f16(<vscale x 8 x half>, <vscale x 8 x half>, i32)
declare <vscale x 2 x float> @llvm.vector.splice.nxv2f32(<vscale x 2 x float>, <vscale x 2 x float>, i32)
declare <vscale x 4 x float> @llvm.vector.splice.nxv4f32(<vscale x 4 x float>, <vscale x 4 x float>, i32)
declare <vscale x 16 x float> @llvm.vector.splice.nxv16f32(<vscale x 16 x float>, <vscale x 16 x float>, i32)
declare <vscale x 2 x double> @llvm.vector.splice.nxv2f64(<vscale x 2 x double>, <vscale x 2 x double>, i32)

declare <vscale x 2 x bfloat> @llvm.vector.splice.nxv2bf16(<vscale x 2 x bfloat>, <vscale x 2 x bfloat>, i32)
declare <vscale x 4 x bfloat> @llvm.vector.splice.nxv4bf16(<vscale x 4 x bfloat>, <vscale x 4 x bfloat>, i32)
declare <vscale x 8 x bfloat> @llvm.vector.splice.nxv8bf16(<vscale x 8 x bfloat>, <vscale x 8 x bfloat>, i32)
